{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1439e7b",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "#### Data Acquisition\n",
    "\n",
    "These exercises should go in a notebook or script named wrangle. Add, commit, and push your changes.\n",
    "\n",
    "This exercises use the cases, dept, and source tables from the 311_data on the Codeup MySQL server.\n",
    "\n",
    "Read the case, department, and source data into their own spark dataframes.\n",
    "\n",
    "Let's see how writing to the local disk works in spark:\n",
    "\n",
    "- Write the code necessary to store the source data in both csv and json format, store these as sources_csv and sources_json\n",
    "\n",
    "- Inspect your folder structure. What do you notice?\n",
    "\n",
    "- Inspect the data in your dataframes. Are the data types appropriate? Write the code necessary to cast the values to the appropriate types.\n",
    "\n",
    "- How old is the latest (in terms of days past SLA) currently open issue? How long has the oldest (in terms of days since opened) currently opened issue been open?\n",
    "\n",
    "- How many Stray Animal cases are there?\n",
    "\n",
    "- How many service requests that are assigned to the Field Operations department (dept_division) are not classified as \"Officer Standby\" request type (service_request_type)?\n",
    "\n",
    "- Convert the council_district column to a string column.\n",
    "\n",
    "- Extract the year from the case_closed_date column.\n",
    "\n",
    "- Convert num_days_late from days to hours in new columns num_hours_late.\n",
    "\n",
    "- Join the case data with the source and department data.\n",
    "\n",
    "- Are there any cases that do not have a request source?\n",
    "\n",
    "- What are the top 10 service request types in terms of number of requests?\n",
    "\n",
    "- What are the top 10 service request types in terms of average days late?\n",
    "\n",
    "- Does number of days late depend on department?\n",
    "\n",
    "- How do number of days late depend on department and request type?\n",
    "\n",
    "- You might have noticed that the latest date in the dataset is fairly far off from the present day. To account for this, replace any occurances of the current time with the maximum date from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c18bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cea614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_url(db, user=env.user, host=env.host, password=env.password):\n",
    "    return (f'mysql+pymysql://{user}:{password}@{host}/{db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e09e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/21 15:59:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/21 15:59:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/21 15:59:41 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/10/21 15:59:41 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://dashiells-air:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x13d3189d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4271deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_db_url('311_data')\n",
    "query = '''select * from cases c\n",
    "            left join dept d on c.dept_division = d.dept_division\n",
    "            left join source s on c.source_id = s.source_id;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a01e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.read_sql(query, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b75022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_opened_date</th>\n",
       "      <th>case_closed_date</th>\n",
       "      <th>SLA_due_date</th>\n",
       "      <th>case_late</th>\n",
       "      <th>num_days_late</th>\n",
       "      <th>case_closed</th>\n",
       "      <th>dept_division</th>\n",
       "      <th>service_request_type</th>\n",
       "      <th>SLA_days</th>\n",
       "      <th>...</th>\n",
       "      <th>source_id</th>\n",
       "      <th>request_address</th>\n",
       "      <th>council_district</th>\n",
       "      <th>dept_division</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>standardized_dept_name</th>\n",
       "      <th>dept_subject_to_SLA</th>\n",
       "      <th>index</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014127332</td>\n",
       "      <td>1/1/18 0:42</td>\n",
       "      <td>1/1/18 12:29</td>\n",
       "      <td>9/26/20 0:42</td>\n",
       "      <td>NO</td>\n",
       "      <td>-998.508762</td>\n",
       "      <td>YES</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Stray Animal</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>svcCRMLS</td>\n",
       "      <td>2315  EL PASO ST, San Antonio, 78207</td>\n",
       "      <td>5</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Animal Care Services</td>\n",
       "      <td>Animal Care Services</td>\n",
       "      <td>YES</td>\n",
       "      <td>132</td>\n",
       "      <td>svcCRMLS</td>\n",
       "      <td>svcCRMLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1014127333</td>\n",
       "      <td>1/1/18 0:46</td>\n",
       "      <td>1/3/18 8:11</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-2.012604</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.322222</td>\n",
       "      <td>...</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>2215  GOLIAD RD, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Trans &amp; Cap Improvements</td>\n",
       "      <td>Trans &amp; Cap Improvements</td>\n",
       "      <td>YES</td>\n",
       "      <td>133</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>svcCRMSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1014127334</td>\n",
       "      <td>1/1/18 0:48</td>\n",
       "      <td>1/2/18 7:57</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-3.022338</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.320729</td>\n",
       "      <td>...</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>102  PALFREY ST W, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Trans &amp; Cap Improvements</td>\n",
       "      <td>Trans &amp; Cap Improvements</td>\n",
       "      <td>YES</td>\n",
       "      <td>133</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>svcCRMSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014127335</td>\n",
       "      <td>1/1/18 1:29</td>\n",
       "      <td>1/2/18 8:13</td>\n",
       "      <td>1/17/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-15.011481</td>\n",
       "      <td>YES</td>\n",
       "      <td>Code Enforcement</td>\n",
       "      <td>Front Or Side Yard Parking</td>\n",
       "      <td>16.291887</td>\n",
       "      <td>...</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>114  LA GARDE ST, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "      <td>Code Enforcement</td>\n",
       "      <td>Code Enforcement Services</td>\n",
       "      <td>DSD/Code Enforcement</td>\n",
       "      <td>YES</td>\n",
       "      <td>133</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>svcCRMSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1014127336</td>\n",
       "      <td>1/1/18 1:34</td>\n",
       "      <td>1/1/18 13:29</td>\n",
       "      <td>1/1/18 4:34</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.372164</td>\n",
       "      <td>YES</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Animal Cruelty(Critical)</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>734  CLEARVIEW DR, San Antonio, 78228</td>\n",
       "      <td>7</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Animal Care Services</td>\n",
       "      <td>Animal Care Services</td>\n",
       "      <td>YES</td>\n",
       "      <td>133</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>svcCRMSS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id case_opened_date case_closed_date  SLA_due_date case_late  \\\n",
       "0  1014127332      1/1/18 0:42     1/1/18 12:29  9/26/20 0:42        NO   \n",
       "1  1014127333      1/1/18 0:46      1/3/18 8:11   1/5/18 8:30        NO   \n",
       "2  1014127334      1/1/18 0:48      1/2/18 7:57   1/5/18 8:30        NO   \n",
       "3  1014127335      1/1/18 1:29      1/2/18 8:13  1/17/18 8:30        NO   \n",
       "4  1014127336      1/1/18 1:34     1/1/18 13:29   1/1/18 4:34       YES   \n",
       "\n",
       "   num_days_late case_closed     dept_division        service_request_type  \\\n",
       "0    -998.508762         YES  Field Operations                Stray Animal   \n",
       "1      -2.012604         YES       Storm Water      Removal Of Obstruction   \n",
       "2      -3.022338         YES       Storm Water      Removal Of Obstruction   \n",
       "3     -15.011481         YES  Code Enforcement  Front Or Side Yard Parking   \n",
       "4       0.372164         YES  Field Operations    Animal Cruelty(Critical)   \n",
       "\n",
       "     SLA_days  ...  source_id                        request_address  \\\n",
       "0  999.000000  ...   svcCRMLS   2315  EL PASO ST, San Antonio, 78207   \n",
       "1    4.322222  ...   svcCRMSS    2215  GOLIAD RD, San Antonio, 78223   \n",
       "2    4.320729  ...   svcCRMSS  102  PALFREY ST W, San Antonio, 78223   \n",
       "3   16.291887  ...   svcCRMSS   114  LA GARDE ST, San Antonio, 78223   \n",
       "4    0.125000  ...   svcCRMSS  734  CLEARVIEW DR, San Antonio, 78228   \n",
       "\n",
       "  council_district     dept_division                  dept_name  \\\n",
       "0                5  Field Operations       Animal Care Services   \n",
       "1                3       Storm Water   Trans & Cap Improvements   \n",
       "2                3       Storm Water   Trans & Cap Improvements   \n",
       "3                3  Code Enforcement  Code Enforcement Services   \n",
       "4                7  Field Operations       Animal Care Services   \n",
       "\n",
       "     standardized_dept_name dept_subject_to_SLA index  source_id  \\\n",
       "0      Animal Care Services                 YES   132   svcCRMLS   \n",
       "1  Trans & Cap Improvements                 YES   133   svcCRMSS   \n",
       "2  Trans & Cap Improvements                 YES   133   svcCRMSS   \n",
       "3      DSD/Code Enforcement                 YES   133   svcCRMSS   \n",
       "4      Animal Care Services                 YES   133   svcCRMSS   \n",
       "\n",
       "  source_username  \n",
       "0        svcCRMLS  \n",
       "1        svcCRMSS  \n",
       "2        svcCRMSS  \n",
       "3        svcCRMSS  \n",
       "4        svcCRMSS  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "213d6cca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "name already used as a name or title",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cases \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpandas_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/session.py:891\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    888\u001b[0m     has_pandas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pandas\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m--> 891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSparkSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dataframe(\n\u001b[1;32m    895\u001b[0m     data, schema, samplingRatio, verifySchema  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    896\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:436\u001b[0m, in \u001b[0;36mSparkConversionMixin.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    434\u001b[0m             warn(msg)\n\u001b[1;32m    435\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m converted_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_from_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimezone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dataframe(converted_data, schema, samplingRatio, verifySchema)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:500\u001b[0m, in \u001b[0;36mSparkConversionMixin._convert_from_pandas\u001b[0;34m(self, pdf, schema, timezone)\u001b[0m\n\u001b[1;32m    495\u001b[0m             pdf[column] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[1;32m    496\u001b[0m                 ser\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_pytimedelta(), index\u001b[38;5;241m=\u001b[39mser\u001b[38;5;241m.\u001b[39mindex, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mser\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    497\u001b[0m             )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# Convert pandas.DataFrame to list of numpy records\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m np_records \u001b[38;5;241m=\u001b[39m \u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# Check if any columns need to be fixed for Spark to infer properly\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np_records) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:2438\u001b[0m, in \u001b[0;36mDataFrame.to_records\u001b[0;34m(self, index, column_dtypes, index_dtypes)\u001b[0m\n\u001b[1;32m   2435\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_mapping\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m specified for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 2438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnames\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformats\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mformats\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/numpy/core/records.py:653\u001b[0m, in \u001b[0;36mfromarrays\u001b[0;34m(arrayList, dtype, shape, formats, names, titles, aligned, byteorder)\u001b[0m\n\u001b[1;32m    650\u001b[0m     formats \u001b[38;5;241m=\u001b[39m [obj\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m arrayList]\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 653\u001b[0m     descr \u001b[38;5;241m=\u001b[39m \u001b[43msb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    655\u001b[0m     descr \u001b[38;5;241m=\u001b[39m format_parser(formats, names, titles, aligned, byteorder)\u001b[38;5;241m.\u001b[39mdtype\n",
      "\u001b[0;31mValueError\u001b[0m: name already used as a name or title"
     ]
    }
   ],
   "source": [
    "cases = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62f319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
